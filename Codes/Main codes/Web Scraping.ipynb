{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Web Scraping.ipynb","provenance":[],"collapsed_sections":["0f215-wq6FKv","sSwWIy0N6Itf","4I4LlDZYtw8C","wIMwDNBK9N4-","7i11TYUE_Goe","PxxWK7_t7mxH","hc5UEqjH7wUz","yR4Mc9rX9WyC","RN36E1zw9jrc","5nR3a79wNy3R","QjaCUusEN5Qx","wTlVQcYrN--H","_j2qnpxVYRdJ","aI9VepVoYepP","YLS7JkAEYion","2EkBgos1Yohh","6EwJjJcar1F_"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"owD8JynXt3ay","colab_type":"text"},"source":["#Setup"]},{"cell_type":"markdown","metadata":{"id":"sDtwzqxY6DIk","colab_type":"text"},"source":["##Google Drive"]},{"cell_type":"code","metadata":{"id":"HGfTDWJljZiF","colab_type":"code","colab":{}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import os\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0f215-wq6FKv","colab_type":"text"},"source":["##Chrome Driver"]},{"cell_type":"code","metadata":{"id":"52wIRH5Ht2sd","colab_type":"code","outputId":"bee9e3d5-e33a-4a01-d11c-4a45b642066a","executionInfo":{"status":"ok","timestamp":1574550178158,"user_tz":300,"elapsed":46899,"user":{"displayName":"Skand Upmanyu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDucdWRvThRuOGGMpf4XuCLzSwgNJW97EO8v5sS=s64","userId":"14474330947256204580"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# install chromium, its driver, and selenium\n","!pip install selenium\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","from selenium.webdriver.chrome.options import Options\n","from selenium import webdriver\n","# set options to be headless, ..\n","\n","options = webdriver.ChromeOptions()\n","options.add_argument('--headless')\n","options.add_argument('--no-sandbox')\n","options.add_argument('--disable-dev-shm-usage')\n","\n","chrome_options = Options()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","driver = webdriver.Chrome(chrome_options=chrome_options)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting selenium\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n","\u001b[K     |████████████████████████████████| 911kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n","Installing collected packages: selenium\n","Successfully installed selenium-3.141.0\n","Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [736 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [787 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,031 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,314 kB]\n","Fetched 4,124 kB in 7s (558 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 32 not upgraded.\n","Need to get 71.9 MB of archives.\n","After this operation, 257 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 78.0.3904.108-0ubuntu0.18.04.1 [1,078 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 78.0.3904.108-0ubuntu0.18.04.1 [63.3 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 78.0.3904.108-0ubuntu0.18.04.1 [3,076 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 78.0.3904.108-0ubuntu0.18.04.1 [4,466 kB]\n","Fetched 71.9 MB in 15s (4,645 kB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 145605 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_78.0.3904.108-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (78.0.3904.108-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_78.0.3904.108-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (78.0.3904.108-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_78.0.3904.108-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (78.0.3904.108-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_78.0.3904.108-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (78.0.3904.108-0ubuntu0.18.04.1) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Setting up chromium-codecs-ffmpeg-extra (78.0.3904.108-0ubuntu0.18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Setting up chromium-browser (78.0.3904.108-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (78.0.3904.108-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (78.0.3904.108-0ubuntu0.18.04.1) ...\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: use options instead of chrome_options\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"sSwWIy0N6Itf","colab_type":"text"},"source":["##Import Packages"]},{"cell_type":"code","metadata":{"id":"hDT9z_eq3teQ","colab_type":"code","colab":{}},"source":["import requests\n","from bs4 import BeautifulSoup\n","import json\n","import pickle\n","import time\n","import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dl2BWEr9tsab","colab_type":"text"},"source":["#Web scraping for review"]},{"cell_type":"markdown","metadata":{"id":"4I4LlDZYtw8C","colab_type":"text"},"source":["##Getting product IDs and image links"]},{"cell_type":"code","metadata":{"id":"T-dYzcuytrEQ","colab_type":"code","outputId":"dcd26d95-2ec6-4253-ec30-09bc9f3e7bb4","executionInfo":{"status":"ok","timestamp":1574552595067,"user_tz":300,"elapsed":2410777,"user":{"displayName":"Skand Upmanyu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDucdWRvThRuOGGMpf4XuCLzSwgNJW97EO8v5sS=s64","userId":"14474330947256204580"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["# No. of pages\n","start = 1\n","end = 301\n","\n","# Initialize dictionary\n","id_link = {}\n","\n","# Loop over all pages\n","for i in range(start,end+1):\n","  # print iteration number\n","  if i%20 == 0:\n","    print(i)\n","  \n","  # create url\n","  url = \"https://www.renttherunway.com/products?sort=recommended&filters%5Bzip_code%5D=10001&_=1574453268488&page=\" + str(i)\n","\n","  # get response\n","  driver.get(url)\n","  time.sleep(2)\n","  response_content = driver.page_source\n","  results_page = BeautifulSoup(response_content,'lxml')\n","\n","  # get button tags\n","  button_tags = results_page.find_all('button',{\"class\":\"heart__button heart__button--minimal\"})\n","\n","  # get item_ids (data-style-name attribute)\n","  style_name = []\n","  for item in button_tags:\n","    style_name.append((item.get('data-style-name')))  \n","\n","  #  get div tags for images\n","  div_tags = results_page.find_all('div',{\"class\":\"grid-product-card-image cycle-image cycle-image-0\"})\n","\n","  # get img tags for images\n","  img_tags = []\n","  for item in div_tags:\n","    img_tags.append(item.find('img'))\n","\n","  # get item links\n","  item_links = []\n","  for item in img_tags:\n","    item_links.append(item.get('src'))\n","\n","  # create dictionary of item_id, item_link\n","  for k,v in zip(style_name,item_links):\n","    id_link[k] = v"],"execution_count":0,"outputs":[{"output_type":"stream","text":["20\n","40\n","60\n","80\n","100\n","120\n","140\n","160\n","180\n","200\n","220\n","240\n","260\n","280\n","300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bwYc29LFoMfr","colab_type":"code","colab":{}},"source":["with open('id_link.pkl', 'wb') as f:\n","    pickle.dump(id_link, f)\n","\n","# save to drive\n","link = 'https://drive.google.com/open?id=11mLhhzlzjCeArB4oE0F957IgaxHdG5et'\n","_, id = link.split(\"=\")\n","\n","# get the folder id where you want to save your file\n","file = drive.CreateFile({'parents':[{u'id': id}]})\n","file.SetContentFile('id_link.pkl')\n","file.Upload() "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"szY7EJa97cA-","colab_type":"text"},"source":["##Get all Product attributes and Review data"]},{"cell_type":"markdown","metadata":{"id":"c9dtM6y09HAh","colab_type":"text"},"source":["###Define function for one Product URL"]},{"cell_type":"code","metadata":{"id":"j8Ypt-WSu98i","colab_type":"code","colab":{}},"source":["def get_metadata(url):\n","  \n","  #get response\n","  response = requests.get(url)\n","  results_page = BeautifulSoup(response.content,'lxml')\n","\n","  # get script tag\n","  script_tags = results_page.find_all('script')\n","\n","  # find text beginning with ReactReduxInitializer\n","  for item in script_tags:\n","    text = item.get_text().strip()\n","    if text.startswith('ReactReduxInitializer'):\n","      script_string = text\n","\n","  # Convert to JSON\n","  pos = script_string.find('{') #find {\n","  json_string = script_string[pos:-2] #remove ;\n","  metadata = json.loads(json_string) #load to json dict\n","  product_data = metadata['product'] #get product dict\n","  review_data = metadata['reviews'] #get review dict\n","  return product_data, review_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wIMwDNBK9N4-","colab_type":"text"},"source":["###Run over all Product URLs"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Nnz6P9BBxXw_","colab":{}},"source":["product_data_list = []\n","review_data_list = []\n","i = 1\n","for id_ in id_link.keys():\n","  print(i)\n","  i+=1\n","  url = 'https://www.renttherunway.com/product_reviews/' + id_\n","  product_data, review_data = get_metadata(url)\n","  product_data_list.append(product_data)\n","  review_data_list.append(review_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhWl8fjokDwy","colab_type":"code","colab":{}},"source":["# make pickle file\n","pkl_product = 'product_data_list' + str(start) + '_' + str(end) + '.pkl'\n","pkl_review = 'review_data_list' + str(start) + '_' + str(end) + '.pkl'\n","\n","with open(pkl_product, 'wb') as f:\n","    pickle.dump(product_data_list, f)\n","\n","# save to drive\n","link = 'https://drive.google.com/open?id=1tQpenCBv0HU9ekuEvrA1gdqg99mxnUL8'\n","_, id = link.split(\"=\")\n","\n","# get the folder id where you want to save your file\n","file = drive.CreateFile({'parents':[{u'id': id}]})\n","file.SetContentFile(pkl_product)\n","file.Upload() \n","\n","with open(pkl_review, 'wb') as f:\n","    pickle.dump(review_data_list, f)\n","\n","# get the folder id where you want to save your file\n","file = drive.CreateFile({'parents':[{u'id': id}]})\n","file.SetContentFile(pkl_review)\n","file.Upload() \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7i11TYUE_Goe","colab_type":"text"},"source":["###Download pickle files to Colab Cloud"]},{"cell_type":"code","metadata":{"id":"8Om573mU_Fbg","colab_type":"code","outputId":"902263cd-b1bc-4cc2-bef5-d825c5f1ef82","executionInfo":{"status":"ok","timestamp":1574552786513,"user_tz":300,"elapsed":12872,"user":{"displayName":"Skand Upmanyu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDucdWRvThRuOGGMpf4XuCLzSwgNJW97EO8v5sS=s64","userId":"14474330947256204580"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# choose a local (colab) directory to store the data.\n","local_download_path = os.path.expanduser('~/data/pickle/')\n","try:\n","  os.makedirs(local_download_path)\n","except: pass\n","\n","# 2. Auto-iterate using the query syntax\n","#    https://developers.google.com/drive/v2/web/search-parameters\n","file_list = drive.ListFile(\n","    {'q': \"'11mLhhzlzjCeArB4oE0F957IgaxHdG5et' in parents\"}).GetList()\n","\n","for f in file_list:\n","  # 3. Create & download by id.\n","  print('title: %s, id: %s' % (f['title'], f['id']))\n","  fname = os.path.join(local_download_path, f['title'])\n","  print('downloading to {}'.format(fname))\n","  f_ = drive.CreateFile({'id': f['id']})\n","  f_.GetContentFile(fname)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["title: id_link.pkl, id: 1fDN_D2b7NA6-rk1dLH5zlwaqfo0OS27d\n","downloading to /root/data/pickle/id_link.pkl\n","title: all_review_data_list.pkl, id: 1xoD2dCAghDOVq6z97UAhpl_lC_-aPqph\n","downloading to /root/data/pickle/all_review_data_list.pkl\n","title: all_product_data_list.pkl, id: 1g_fXH7Dx348OL06Yc3z0j_VbVHdcRzqz\n","downloading to /root/data/pickle/all_product_data_list.pkl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pQUm9eGij6Rb","colab_type":"code","colab":{}},"source":["# retrieve data from pickle files\n","pkl_product_file = '/root/data/pickle/all_product_data_list.pkl'\n","pkl_review_file = '/root/data/pickle/all_review_data_list.pkl'\n","\n","# product_data_list\n","with open(pkl_product_file, 'rb') as f:\n","  product_data_list = pickle.load(f)\n","  \n","# product_review_list\n","with open(pkl_review_file, 'rb') as f:\n","  review_data_list = pickle.load(f)\n","\n","# print(len(product_data_list), len(product_review_list))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzBC_Uipp-W8","colab_type":"code","outputId":"973d248c-e392-4530-eaae-9785cfd622ea","executionInfo":{"status":"ok","timestamp":1574552806985,"user_tz":300,"elapsed":578,"user":{"displayName":"Skand Upmanyu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDucdWRvThRuOGGMpf4XuCLzSwgNJW97EO8v5sS=s64","userId":"14474330947256204580"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# retrieve id_link from pickle file\n","with open('id_link.pkl', 'rb') as f:\n","  id_link = pickle.load(f)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18049"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"PxxWK7_t7mxH","colab_type":"text"},"source":["##Get Product attributes based on Product ID"]},{"cell_type":"markdown","metadata":{"id":"enZgGpAR86xd","colab_type":"text"},"source":["###Define function for individual product"]},{"cell_type":"code","metadata":{"id":"hrrAzvKpCYj8","colab_type":"code","colab":{}},"source":["def get_product_details(product_data):\n","\n","  # get product id\n","  k = product_data['id']\n","\n","  # initialize dict\n","  inner_dict = {}\n","\n","  # define columns to keep\n","  cols_to_keep = ['ageRanges','bodyTypes','colors','created','designer','displayName','embellishments','formality','formalityScore','length','neckline',\\\n","                  'occasions','price','productDetails','retailPrice','season','sleeve','stylistNotes']\n","\n","  # iterate over all attributes\n","  for key in product_data.keys():\n","    if key in cols_to_keep:\n","      if key == 'designer':\n","        inner_dict['designer_name'] = product_data[key].get('displayName')\n","      elif key == 'price':\n","        inner_dict['price_base'] = product_data[key].get('base')\n","        inner_dict['price_adjusted'] = product_data[key].get('adjusted')\n","      else:\n","        inner_dict[key] = product_data[key]\n","  return k, inner_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rXI2UtVM8_BO","colab_type":"text"},"source":["###Run over all products"]},{"cell_type":"code","metadata":{"id":"nauEI0s1zlZE","colab_type":"code","colab":{}},"source":["# intialize dict\n","product_dict = {}\n","\n","# iterate over all products\n","for item in product_data_list:\n","  k, inner_dict = get_product_details(item)\n","  product_dict[k] = inner_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hc5UEqjH7wUz","colab_type":"text"},"source":["##Get user reviews for products"]},{"cell_type":"markdown","metadata":{"id":"yR4Mc9rX9WyC","colab_type":"text"},"source":["###Define function for getting reviews for one product from all users"]},{"cell_type":"code","metadata":{"id":"JMpvj_o3HIVp","colab_type":"code","colab":{}},"source":["def get_product_review(review_data):\n","\n","  # If there is at least one review\n","  if len(review_data['data']) != 0:\n","    # get product id\n","    item_id = review_data['data'][0].get('moment')['styleName']\n","\n","    # initialize dictionary\n","    inner_dict = {}\n","\n","    # get review summary\n","    inner_dict['summary'] = {'count': review_data.get('count'), \n","                            'currentCount': review_data.get('currentCount'), \n","                              'averageRating': review_data.get('averageRating')\n","                              }\n","\n","    # get individual reviews\n","    n_reviews = len(review_data['data'])\n","\n","    # initialize dictionary\n","    inner_dict['reviews'] = {}\n","\n","    # iterate over all reviews by users\n","    for i in range(n_reviews):\n","\n","      # get data\n","      data = review_data['data'][i].get('moment')\n","      user_dict = {}\n","      user_review_dict = {}\n","\n","      # get user attributes\n","      user_id = data['userId'] #user id\n","\n","      # user attributes\n","      user_dict = {'age': review_data['data'][i]['user'].get('age'),\n","                  'birthday': review_data['data'][i]['user'].get('birthday'),\n","                  'bodyType' : review_data['data'][i]['user'].get('bodyType'),\n","                  'bustSize' : review_data['data'][i]['user'].get('bustSize'),\n","                  'numReviewsByUser' : data.get('numReviewsByUser'),\n","                  'height' : review_data['data'][i]['user'].get('height'),\n","                  'heightInches' : review_data['data'][i]['user'].get('heightInches'),\n","                  'joined' : review_data['data'][i]['user'].get('joined'),\n","                  'nickName' : review_data['data'][i]['user'].get('nickName'),\n","                  'standardSize' : review_data['data'][i]['user'].get('standardSize'),\n","                  'usStandardSize' : review_data['data'][i]['user'].get('usStandardSize'),\n","                  'weight' : review_data['data'][i]['user'].get('weight'),\n","                  'weightPounds' : review_data['data'][i]['user'].get('weightPounds'),\n","                  }\n","\n","      # get review data\n","      user_review_dict = {\n","                          'caption': data.get('caption'),\n","                          'content': data.get('content'),\n","                          'fit': data.get('fit'),\n","                          'rating': data.get('rating'),\n","                          'reviewId': data.get('reviewId'),\n","                          'uploadedAt': data.get('uploadedAt')\n","                          }\n","\n","      # set review data to dictionary\n","      inner_dict['reviews'][user_id] = {\n","                                        'userData': user_dict, \n","                                        'userReview': user_review_dict\n","                                        }\n","\n","  # if no reviews return None\n","  else:\n","    item_id, inner_dict = (None, None)\n","  return item_id, inner_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RN36E1zw9jrc","colab_type":"text"},"source":["###Getting reviews for all products from all users"]},{"cell_type":"code","metadata":{"id":"V9IjlW7kl7GI","colab_type":"code","colab":{}},"source":["# initialize dictionary\n","all_review_dict = {}\n","\n","# iterate over all products\n","for item in review_data_list:\n","  # get product reviews for a product\n","  item_id, review_data = get_product_review(item)\n","\n","  # if there is more than 1 review\n","  if review_data != None:\n","    all_review_dict[item_id] = review_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5nR3a79wNy3R","colab_type":"text"},"source":["##Convert scraped data to Dataframe"]},{"cell_type":"markdown","metadata":{"id":"QjaCUusEN5Qx","colab_type":"text"},"source":["###Product data"]},{"cell_type":"code","metadata":{"id":"jyun182BBArm","colab_type":"code","colab":{}},"source":["# Convert product_dic to dataframe\n","df_products = pd.DataFrame(product_dict).T"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTlVQcYrN--H","colab_type":"text"},"source":["###Review data"]},{"cell_type":"code","metadata":{"id":"D6MF2JNOHfjv","colab_type":"code","colab":{}},"source":["# This is a multi level dictionary, therefore, we need to restructure it to convert to dataframe\n","\n","# initalize dictionary\n","df_dict = {}\n","\n","# iterate over all products\n","for item_id, inner_dict in all_review_dict.items():\n","  # get product level data for reviews (summary)\n","  averageRating = inner_dict['summary'].get('averageRating')\n","  count = inner_dict['summary'].get('count')\n","  currentCount = inner_dict['summary'].get('currentCount')\n","\n","  # iterate over all user reviews\n","  for user, details in inner_dict['reviews'].items():\n","    # Define key as combination of (item_id, averageRating, count, currentCount, user)\n","    key = (item_id, averageRating, count, currentCount, user)\n","\n","    # Columns should be userData and userReview data\n","    userData_dict = details['userData']\n","    userReview_dict = details['userReview']\n","\n","    # append userData and userReview dictionaries\n","    userData_dict.update(userReview_dict)\n","\n","    # assign create key values pair to dictionary\n","    df_dict[key] = userData_dict\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVzndMjCJKna","colab_type":"code","colab":{}},"source":["# Convert to dataframe\n","df_review = pd.DataFrame(df_dict).T.reset_index()\n","\n","# Rename columns which have been reset\n","df_review = df_review.rename(columns={\"level_0\": \"item_id\",\n","                        \"level_1\": \"averageRating\",\n","                        \"level_2\": \"countRatings\",\n","                        \"level_3\": \"currentCount\",\n","                        \"level_4\": \"user_id\"\n","                        })"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_j2qnpxVYRdJ","colab_type":"text"},"source":["##Fixing columns"]},{"cell_type":"markdown","metadata":{"id":"aI9VepVoYepP","colab_type":"text"},"source":["###Function to get unique items in columns with entries as list"]},{"cell_type":"code","metadata":{"id":"zi_kz13xA_eM","colab_type":"code","colab":{}},"source":["def unique_cols(df, col):\n","  # intialize list\n","  uniq_list = []\n","  # iterate over columns values\n","  for list_item in df[col].values:\n","    # if not nan\n","    if type(list_item) == list:\n","      for item in list_item:\n","        if item not in uniq_list:\n","          uniq_list.append(item)\n","  return uniq_list"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLS7JkAEYion","colab_type":"text"},"source":["###Function to convert column with list to dummy variables"]},{"cell_type":"code","metadata":{"id":"Nq2V1iAABqnZ","colab_type":"code","colab":{}},"source":["def list_to_cols(df, col):\n","  #replace nans\n","  df[col] = df[col].fillna('NA')\n","\n","  #get unique cols\n","  uniq_items = unique_cols(df, col)\n","\n","  #create columns\n","  for uniq_item in uniq_items:\n","    df[col + '_' + uniq_item] = 0\n","    for i in range(df.shape[0]):\n","      if (type(df[col][i]) == list) & (uniq_item in df[col][i]):\n","        df[col + '_' + uniq_item][i] = 1\n","      else:\n","        df[col + '_' + uniq_item][i] = 0\n","  return df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2EkBgos1Yohh","colab_type":"text"},"source":["###Convert list items to dummy variables"]},{"cell_type":"code","metadata":{"id":"aJCPLYTKCyIh","colab_type":"code","outputId":"71b4115f-16e2-4cbf-ca68-78cecebf48e8","executionInfo":{"status":"ok","timestamp":1574552991405,"user_tz":300,"elapsed":108550,"user":{"displayName":"Skand Upmanyu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDucdWRvThRuOGGMpf4XuCLzSwgNJW97EO8v5sS=s64","userId":"14474330947256204580"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# ageRanges\n","df_products = list_to_cols(df_products, 'ageRanges')\n","df_products = df_products.drop(columns = ['ageRanges'])\n","\n","# bodyTypes\n","df_products = list_to_cols(df_products, 'bodyTypes')\n","df_products = df_products.drop(columns = ['bodyTypes'])\n","\n","# colors\n","df_products = list_to_cols(df_products, 'colors')\n","df_products = df_products.drop(columns = ['colors'])\n","\n","# formality\n","df_products = list_to_cols(df_products, 'formality')\n","df_products = df_products.drop(columns = ['formality'])\n","\n","# occasions\n","df_products = list_to_cols(df_products, 'occasions')\n","df_products = df_products.drop(columns = ['occasions'])\n","\n","# embellishments\n","df_products = list_to_cols(df_products, 'embellishments')\n","df_products = df_products.drop(columns = ['embellishments'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  from ipykernel import kernelapp as app\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6EwJjJcar1F_","colab_type":"text"},"source":["###Join image links to dataframes"]},{"cell_type":"code","metadata":{"id":"cGhsGCnncPwk","colab_type":"code","colab":{}},"source":["df_id_link = pd.DataFrame.from_dict(id_link, orient='index')\n","df_id_link.columns = ['product_img_link']\n","\n","# products\n","df_products = df_products.join(df_id_link)\n","\n","# reviews\n","df_review = df_review.join(df_id_link, on='item_id')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CNeDAGDUcMxO","colab_type":"text"},"source":["#Export processed data to pickle file"]},{"cell_type":"markdown","metadata":{"id":"0zbIL27qspBW","colab_type":"text"},"source":["##Products"]},{"cell_type":"code","metadata":{"id":"V49s8lkusg5_","colab_type":"code","colab":{}},"source":["with open('products_processed.pkl', 'wb') as f:\n","    pickle.dump(df_products, f)\n","\n","# save to drive\n","link = 'https://drive.google.com/open?id=11mLhhzlzjCeArB4oE0F957IgaxHdG5et'\n","_, id = link.split(\"=\")\n","\n","# get the folder id where you want to save your file\n","file = drive.CreateFile({'parents':[{u'id': id}]})\n","file.SetContentFile('products_processed.pkl')\n","file.Upload() "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7WPihg5szRb","colab_type":"text"},"source":["##Reviews"]},{"cell_type":"code","metadata":{"id":"-plvv5BFszZn","colab_type":"code","colab":{}},"source":["with open('reviews_processed.pkl', 'wb') as f:\n","    pickle.dump(df_review, f)\n","\n","# save to drive\n","link = 'https://drive.google.com/open?id=11mLhhzlzjCeArB4oE0F957IgaxHdG5et'\n","_, id = link.split(\"=\")\n","\n","# get the folder id where you want to save your file\n","file = drive.CreateFile({'parents':[{u'id': id}]})\n","file.SetContentFile('reviews_processed.pkl')\n","file.Upload() "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RcyvTj5vs8D9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}